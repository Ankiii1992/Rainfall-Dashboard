import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import gspread
from google.oauth2.service_account import Credentials
import json
from datetime import datetime, timedelta
import os
import io
import re

# ---------------------------- CONFIG ----------------------------
@st.cache_resource
def get_gsheet_client():
Â  Â  """
Â  Â  Establishes a connection to Google Sheets using service account credentials.
Â  Â  The credentials should be stored in Streamlit secrets.
Â  Â  """
Â  Â  scope = ["https://www.googleapis.com/auth/spreadsheets", "https://www.googleapis.com/auth/drive"]
Â  Â  try:
Â  Â  Â  Â  creds_dict = st.secrets["gcp_service_account"]
Â  Â  Â  Â  creds = Credentials.from_service_account_info(creds_dict, scopes=scope)
Â  Â  Â  Â  return gspread.authorize(creds)
Â  Â  except Exception as e:
Â  Â  Â  Â  st.error(f"Error connecting to Google Sheets: {e}")
Â  Â  Â  Â  st.info("Please ensure your Google service account credentials are set up correctly in Streamlit's secrets.")
Â  Â  Â  Â  return None

@st.cache_resource
def load_geojson(path):
Â  Â  """Loads GeoJSON data from a local file path."""
Â  Â  if os.path.exists(path):
Â  Â  Â  Â  with open(path, "r", encoding="utf-8") as f:
Â  Â  Â  Â  Â  Â  geojson_data = json.load(f)
Â  Â  Â  Â  return geojson_data
Â  Â  st.error(f"GeoJSON file not found at: {path}")
Â  Â  return None

# --- Custom CSS for Styling ---
st.markdown("""
<style>
Â  Â  html, body, .main {
Â  Â  Â  Â  background-color: #f3f6fa;
Â  Â  Â  Â  font-family: 'Segoe UI', sans-serif;
Â  Â  }
Â  Â  .title-text {
Â  Â  Â  Â  font-size: 2.8rem;
Â  Â  Â  Â  font-weight: 800;
Â  Â  Â  Â  color: #1a237e;
Â  Â  Â  Â  padding: 1rem 0 0.2rem 0;
Â  Â  }
Â  Â  .metric-container {
Â  Â  Â  Â  padding: 0.8rem;
Â  Â  }
Â  Â  .metric-tile {
Â  Â  Â  Â  background: linear-gradient(135deg, #f0faff, #e0f2f1);
Â  Â  Â  Â  padding: 1.2rem 1.4rem 1rem 1.4rem;
Â  Â  Â  Â  border-radius: 1.25rem;
Â  Â  Â  Â  box-shadow: 0 6px 16px rgba(0, 0, 0, 0.06);
Â  Â  Â  Â  text-align: center;
Â  Â  Â  Â  transition: 0.3s ease;
Â  Â  Â  Â  border: 1px solid #c5e1e9;
Â  Â  Â  Â  height: 165px;
Â  Â  Â  Â  display: flex;
Â  Â  Â  Â  flex-direction: column;
Â  Â  Â  Â  justify-content: center;
Â  Â  }
Â  Â  .metric-tile:hover {
Â  Â  Â  Â  transform: translateY(-4px);
Â  Â  Â  Â  box_shadow: 0 10px 28px rgba(0, 0, 0, 0.1);
Â  Â  }
Â  Â  .metric-tile h4 {
Â  Â  Â  Â  color: #01579b;
Â  Â  Â  Â  font-size: 1.05rem;
Â  Â  Â  Â  margin-bottom: 0.2rem;
Â  Â  }
Â  Â  .metric-tile h2 {
Â  Â  Â  Â  font-size: 2.2rem;
Â  Â  Â  Â  color: #0077b6;
Â  Â  Â  Â  margin: 0.1rem 0 0.1rem 0;
Â  Â  Â  Â  font-weight: 700;
Â  Â  }
Â  Â  .metric-tile p {
Â  Â  Â  Â  margin: 0 0 0;
Â  Â  Â  Â  font-size: 0.95rem;
Â  Â  Â  Â  color: #37474f;
Â  Â  }

Â  Â  /* These CSS rules for the download button will likely NOT WORK if unsafe_allow_html=True */
Â  Â  /* does not permit direct injection of elements to hide Streamlit's native components */
Â  Â  .stDataFrame header {
Â  Â  Â  Â  display: none !important;
Â  Â  }
Â  Â  [data-testid="stDataFrameToolbar"] button {
Â  Â  Â  Â  display: none !important;
Â  Â  }
Â  Â  [data-testid="stDataFrameToolbar"] {
Â  Â  Â  Â  display: none !important;
Â  Â  }
</style>

<script>
Â  Â  document.addEventListener('contextmenu', event => event.preventDefault());
</script>
""", unsafe_allow_html=True)


# ---------------------------- RAINFALL CATEGORY LOGIC ----------------------------
color_map = {
Â  Â  "No Rain": "#f8f8f8",
Â  Â  "Very Light": "#e0ffe0",
Â  Â  "Light": "#00ff01",
Â  Â  "Moderate": "#00ffff",
Â  Â  "Rather Heavy": "#ffeb3b",
Â  Â  "Heavy": "#ff8c00",
Â  Â  "Very Heavy": "#d50000",
Â  Â  "Extremely Heavy": "#f820fe",
Â  Â  "Exceptional": "#e8aaf5"
}

category_ranges = { # From reference code
Â  Â  "No Rain": "0 mm",
Â  Â  "Very Light": "0.1 â€“ 2.4 mm",
Â  Â  "Light": "2.5 â€“ 7.5 mm",
Â  Â  "Moderate": "7.6 â€“ 35.5 mm",
Â  Â  "Rather Heavy": "35.6 â€“ 64.4 mm",
Â  Â  "Heavy": "64.5 â€“ 124.4 mm",
Â  Â  "Very Heavy": "124.5 â€“ 244.4 mm",
Â  Â  "Extremely Heavy": "244.5 â€“ 350 mm",
Â  Â  "Exceptional": "> 350 mm"
}

def classify_rainfall(rainfall):
Â  Â  if pd.isna(rainfall) or rainfall == 0:
Â  Â  Â  Â  return "No Rain"
Â  Â  elif rainfall > 0 and rainfall <= 2.4:
Â  Â  Â  Â  return "Very Light"
Â  Â  elif rainfall <= 7.5:
Â  Â  Â  Â  return "Light"
Â  Â  elif rainfall <= 35.5:
Â  Â  Â  Â  return "Moderate"
Â  Â  elif rainfall <= 64.4:
Â  Â  Â  Â  return "Rather Heavy"
Â  Â  elif rainfall <= 124.4:
Â  Â  Â  Â  return "Heavy"
Â  Â  elif rainfall <= 244.4:
Â  Â  Â  Â  return "Very Heavy"
Â  Â  elif rainfall <= 350:
Â  Â  Â  Â  return "Extremely Heavy"
Â  Â  else:
Â  Â  Â  Â  return "Exceptional"

# Ensure the order of categories for the Plotly color scale and legend
ordered_categories = [
Â  Â  "No Rain", "Very Light", "Light", "Moderate", "Rather Heavy",
Â  Â  "Heavy", "Very Heavy", "Extremely Heavy", "Exceptional"
]


# ---------------------------- UTILITY FUNCTIONS ----------------------------

def generate_title_from_date(selected_date):
Â  Â  start_date = (selected_date - timedelta(days=1)).strftime("%d-%m-%Y")
Â  Â  end_date = selected_date.strftime("%d-%m-%Y")
Â  Â  return f"24 Hours Rainfall Summary ({start_date} 06:00 AM to {end_date} 06:00 AM)"

def load_sheet_data(sheet_name, tab_name):
Â  Â  try:
Â  Â  Â  Â  client = get_gsheet_client()
Â  Â  Â  Â  sheet = client.open(sheet_name).worksheet(tab_name)
Â  Â  Â  Â  df = pd.DataFrame(sheet.get_all_records())
Â  Â  Â  Â  df.columns = df.columns.str.strip()
Â  Â  Â  Â  # Ensure column names are consistent early - only rename if 'TOTAL' is present
Â  Â  Â  Â  if 'TOTAL' in df.columns:
Â  Â  Â  Â  Â  Â  df.rename(columns={"DISTRICT": "District", "TALUKA": "Taluka", "TOTAL": "Total_mm"}, inplace=True)
Â  Â  Â  Â  else: # For 2-hourly data where 'TOTAL' might not be a direct column
Â  Â  Â  Â  Â  Â  df.rename(columns={"DISTRICT": "District", "TALUKA": "Taluka"}, inplace=True)
Â  Â  Â  Â  return df
Â  Â  except Exception as e:
Â  Â  Â  Â  # st.error(f"Error loading data from sheet '{sheet_name}', tab '{tab_name}': {e}") # For debugging
Â  Â  Â  Â  return pd.DataFrame() # Return empty DataFrame on failure

# --- START: USER-PROVIDED ZONAL SUMMARY LOGIC ---
def get_zonal_data(df):
Â  Â  """
Â  Â  Generates a zonal summary from a DataFrame that contains all required columns.
Â  Â  It dynamically gets zone names from the data itself.
Â  Â  """
Â  Â  df_copy = df.copy()
Â  Â Â 
Â  Â  # Standardize column names by stripping spaces and converting to lowercase for robust matching
Â  Â  df_copy.columns = [col.strip().lower() for col in df_copy.columns]
Â  Â Â 
Â  Â  # --- ADD THIS NEW LINE TO FIX ZONE TYPOS ---
Â  Â  if 'zone' in df_copy.columns:
Â  Â  Â  Â  df_copy['zone'] = df_copy['zone'].str.strip().str.upper().str.replace('GUJARA T', 'GUJARAT')

Â  Â  # --- NEW LOGIC FOR FLEXIBLE COLUMN MATCHING ---
Â  Â  # Define a mapping from the standardized required name to the column found in the DF
Â  Â  col_mapping = {
Â  Â  Â  Â  'zone': None,
Â  Â  Â  Â  'avg_rain': None,
Â  Â  Â  Â  'rain_till_yesterday': None,
Â  Â  Â  Â  'rain_last_24_hrs': None,
Â  Â  Â  Â  'total_rainfall': None,
Â  Â  Â  Â  'percent_against_avg': None,
Â  Â  }
Â  Â Â 
Â  Â  # Iterate through DF columns and find the best match for each required column
Â  Â  standardized_cols = df_copy.columns
Â  Â  for req_col, _ in col_mapping.items():
Â  Â  Â  Â  if req_col == 'zone':
Â  Â  Â  Â  Â  Â  # Handle the 'zone' column separately
Â  Â  Â  Â  Â  Â  if 'zone' in standardized_cols:
Â  Â  Â  Â  Â  Â  Â  Â  col_mapping['zone'] = 'zone'
Â  Â  Â  Â  Â  Â  elif 'zonedistricttaluka' in standardized_cols:
Â  Â  Â  Â  Â  Â  Â  Â  # This handles the case if the column is a single, combined one
Â  Â  Â  Â  Â  Â  Â  Â  # but we need to split it first. Assuming we only get the simple case now.
Â  Â  Â  Â  Â  Â  Â  Â  st.error("Please ensure 'Zone' is a separate column. The script cannot parse combined 'ZoneDistrictTaluka' header.")
Â  Â  Â  Â  Â  Â  Â  Â  return pd.DataFrame()
Â  Â  Â  Â  elif 'rain_till' in standardized_cols:
Â  Â  Â  Â  Â  Â  col_mapping['rain_till_yesterday'] = 'rain_till'
Â  Â  Â  Â  elif 'rain_last' in standardized_cols:
Â  Â  Â  Â  Â  Â  col_mapping['rain_last_24_hrs'] = 'rain_last'
Â  Â  Â  Â  elif 'total_rain' in standardized_cols:
Â  Â  Â  Â  Â  Â  col_mapping['total_rainfall'] = 'total_rain'
Â  Â  Â  Â  elif 'percent_a' in standardized_cols:
Â  Â  Â  Â  Â  Â  col_mapping['percent_against_avg'] = 'percent_a'
Â  Â  Â  Â  # General case
Â  Â  Â  Â  elif req_col in standardized_cols:
Â  Â  Â  Â  Â  Â  col_mapping[req_col] = req_col
Â  Â Â 
Â  Â  # Check if all required columns were found
Â  Â  for req_col, found_col in col_mapping.items():
Â  Â  Â  Â  if found_col is None:
Â  Â  Â  Â  Â  Â  st.error(f"Required column for '{req_col}' not found in the data source. Please check your sheet headers.")
Â  Â  Â  Â  Â  Â  return pd.DataFrame()

Â  Â  # Rename the columns to the standard format for the rest of the function
Â  Â  df_copy = df_copy.rename(columns={found: req for req, found in col_mapping.items()})
Â  Â Â 
Â  Â  # Check if the renamed columns exist before proceeding
Â  Â  required_cols_standardized = list(col_mapping.keys())
Â  Â  if not all(col in df_copy.columns for col in required_cols_standardized):
Â  Â  Â  Â  st.error("Error standardizing columns. Some required columns are missing.")
Â  Â  Â  Â  return pd.DataFrame()

Â  Â  # Clean the data and convert to numeric, handling potential errors
Â  Â  for col in required_cols_standardized[1:]:
Â  Â  Â  Â  df_copy[col] = df_copy[col].astype(str).str.replace(' mm', '').str.replace('%', '')
Â  Â  Â  Â  df_copy[col] = pd.to_numeric(df_copy[col], errors='coerce')

Â  Â  # Get the unique zones directly from the data and sort them
Â  Â  unique_zones = sorted(df_copy['zone'].unique())

Â  Â  # Group by the dynamically found zone column and calculate averages
Â  Â  zonal_averages = df_copy.groupby('zone')[['avg_rain', 'rain_till_yesterday', 'rain_last_24_hrs', 'total_rainfall', 'percent_against_avg']].mean().round(2)
Â  Â Â 
Â  Â  # Reorder the DataFrame using the unique zones from the data
Â  Â  final_results = zonal_averages.reindex(unique_zones).reset_index()
Â  Â Â 
Â  Â  # Revert column names to the original format for display
Â  Â  final_results = final_results.rename(columns={
Â  Â  Â  Â  'zone': 'Zone',
Â  Â  Â  Â  'avg_rain': 'Avg_Rain',
Â  Â  Â  Â  'rain_till_yesterday': 'Rain_Till_Yesterday',
Â  Â  Â  Â  'rain_last_24_hrs': 'Rain_Last_24_Hrs',
Â  Â  Â  Â  'total_rainfall': 'Total_Rainfall',
Â  Â  Â  Â  'percent_against_avg': 'Percent_Against_Avg'
Â  Â  })

Â  Â  return final_results


def generate_zonal_summary_table(df_zonal_averages, df_full_data):
Â  Â  """Generates a formatted table with zonal averages and a state-wide average row."""
Â  Â  if df_zonal_averages.empty or df_full_data.empty:
Â  Â  Â  Â  return pd.DataFrame()

Â  Â  df_zonal_averages_copy = df_zonal_averages.copy()
Â  Â Â 
Â  Â  # Calculate state-wide averages from the full dataset
Â  Â  state_avg = df_full_data[['Avg_Rain', 'Rain_Till_Yesterday', 'Rain_Last_24_Hrs', 'Total_Rainfall', 'Percent_Against_Avg']].mean().round(2)
Â  Â Â 
Â  Â  # Create a new DataFrame for the state average row
Â  Â  state_avg_row = pd.DataFrame([state_avg.to_dict()])
Â  Â  state_avg_row['Zone'] = 'State Avg.'
Â  Â Â 
Â  Â  # Concatenate the zonal averages with the state average row
Â  Â  final_table = pd.concat([df_zonal_averages_copy, state_avg_row], ignore_index=True)
Â  Â Â 
Â  Â  # Format the columns for display
Â  Â  for col in ['Avg_Rain', 'Rain_Till_Yesterday', 'Rain_Last_24_Hrs', 'Total_Rainfall']:
Â  Â  Â  Â  final_table[col] = final_table[col].astype(str) + ' mm'
Â  Â  final_table['Percent_Against_Avg'] = final_table['Percent_Against_Avg'].astype(str) + '%'
Â  Â Â 
Â  Â  # Rename columns for better display
Â  Â  final_table = final_table.rename(columns={
Â  Â  Â  Â  'Avg_Rain': 'Avg_Rain (mm)',
Â  Â  Â  Â  'Rain_Till_Yesterday': 'Rain_Till_Yesterday (mm)',
Â  Â  Â  Â  'Rain_Last_24_Hrs': 'Rain_Last_24_Hrs (mm)',
Â  Â  Â  Â  'Total_Rainfall': 'Total_Rainfall (mm)',
Â  Â  Â  Â  'Percent_Against_Avg': 'Percent_Against_Avg'
Â  Â  })
Â  Â Â 
Â  Â  return final_table
# --- END: USER-PROVIDED ZONAL SUMMARY LOGIC ---


def create_zonal_dual_axis_chart(data):
Â  Â  """Creates a dual-axis chart for zonal rainfall."""
Â  Â  fig = make_subplots(specs=[[{"secondary_y": True}]])
Â  Â Â 
Â  Â  # The dataframe passed to this function must have standardized column names.
Â  Â  # The user's get_zonal_data renames columns for display, so we have to use
Â  Â  # standardized names for the chart
Â  Â  data = data.rename(columns={
Â  Â  Â  Â  'Zone': 'zone',
Â  Â  Â  Â  'Avg_Rain': 'avg_rain',
Â  Â  Â  Â  'Rain_Till_Yesterday': 'rain_till_yesterday',
Â  Â  Â  Â  'Rain_Last_24_Hrs': 'rain_last_24_hrs',
Â  Â  Â  Â  'Total_Rainfall': 'total_rainfall',
Â  Â  Â  Â  'Percent_Against_Avg': 'percent_against_avg'
Â  Â  })
Â  Â Â 
Â  Â  fig.add_trace(
Â  Â  Â  Â  go.Bar(
Â  Â  Â  Â  Â  Â  x=data['zone'],
Â  Â  Â  Â  Â  Â  y=data['total_rainfall'],
Â  Â  Â  Â  Â  Â  name='Total Rainfall (mm)',
Â  Â  Â  Â  Â  Â  marker_color='rgb(100, 149, 237)',
Â  Â  Â  Â  Â  Â  text=data['total_rainfall'],
Â  Â  Â  Â  Â  Â  textposition='inside',
Â  Â  Â  Â  ),
Â  Â  Â  Â  secondary_y=False,
Â  Â  )
Â  Â Â 
Â  Â  fig.add_trace(
Â  Â  Â  Â  go.Scatter(
Â  Â  Â  Â  Â  Â  x=data['zone'],
Â  Â  Â  Â  Â  Â  y=data['percent_against_avg'],
Â  Â  Â  Â  Â  Â  name='% Against Avg. Rainfall',
Â  Â  Â  Â  Â  Â  mode='lines+markers+text',
Â  Â  Â  Â  Â  Â  marker=dict(size=8, color='rgb(255, 165, 0)'),
Â  Â  Â  Â  Â  Â  line=dict(color='rgb(255, 165, 0)'),
Â  Â  Â  Â  Â  Â  text=[f'{p:.1f}%' for p in data['percent_against_avg']],
Â  Â  Â  Â  Â  Â  textposition='top center',
Â  Â  Â  Â  ),
Â  Â  Â  Â  secondary_y=True,
Â  Â  )
Â  Â Â 
Â  Â  fig.update_layout(
Â  Â  Â  Â  title_text='Zonewise Total Rainfall vs. % Against Average',
Â  Â  Â  Â  height=450,
Â  Â  Â  Â  margin=dict(l=0, r=0, t=50, b=0),
Â  Â  Â  Â  legend=dict(
Â  Â  Â  Â  Â  Â  orientation="h",
Â  Â  Â  Â  Â  Â  yanchor="bottom",
Â  Â  Â  Â  Â  Â  y=-0.3,
Â  Â  Â  Â  Â  Â  xanchor="center",
Â  Â  Â  Â  Â  Â  x=0.5
Â  Â  Â  Â  )
Â  Â  )
Â  Â Â 
Â  Â  fig.update_yaxes(title_text="Total Rainfall (mm)", secondary_y=False)
Â  Â  fig.update_yaxes(title_text="% Against Avg. Rainfall", secondary_y=True)
Â  Â Â 
Â  Â  return fig


# --- plot_choropleth function (for map that plots daily total) ---
def plot_choropleth(df, geojson_path, title="Gujarat Rainfall Distribution", geo_feature_id_key="properties.SUB_DISTRICT", geo_location_col="Taluka"):
Â  Â  # This function is now made more generic to handle both talukas and districts
Â  Â  geojson_data = load_geojson(geojson_path)
Â  Â  if not geojson_data:
Â  Â  Â  Â  return go.Figure()

Â  Â  df_plot = df.copy()

Â  Â  # Determine which column to use for feature linking and what to strip/lower
Â  Â  if geo_location_col == "Taluka":
Â  Â  Â  Â  df_plot["Taluka"] = df_plot["Taluka"].astype(str).str.strip().str.lower()
Â  Â  elif geo_location_col == "District":
Â  Â  Â  Â  df_plot["District"] = df_plot["District"].astype(str).str.strip().str.lower()


Â  Â  # The column for coloring the map should be 'Total_mm' (daily total for taluka)
Â  Â  # or 'District_Avg_Rain_Last_24_Hrs' for district.
Â  Â  color_column = None
Â  Â  if 'Total_mm' in df_plot.columns: # For Talukas
Â  Â  Â  Â  color_column = 'Total_mm'
Â  Â  elif 'District_Avg_Rain_Last_24_Hrs' in df_plot.columns: # For Districts
Â  Â  Â  Â  color_column = 'District_Avg_Rain_Last_24_Hrs'
Â  Â  else:
Â  Â  Â  Â  st.warning(f"Neither 'Total_mm' nor 'District_Avg_Rain_Last_24_Hrs' found for map categorization. Map may not display categories correctly.")
Â  Â  Â  Â  df_plot["Rainfall_Category"] = "No Rain" # Default if data is missing
Â  Â  Â  Â  color_column = "Rainfall_Category"


Â  Â  if color_column:
Â  Â  Â  Â  df_plot[color_column] = pd.to_numeric(df_plot[color_column], errors='coerce')
Â  Â  Â  Â  df_plot["Rainfall_Category"] = df_plot[color_column].apply(classify_rainfall)
Â  Â  Â  Â  df_plot["Rainfall_Category"] = pd.Categorical(
Â  Â  Â  Â  Â  Â  df_plot["Rainfall_Category"],
Â  Â  Â  Â  Â  Â  categories=ordered_categories,
Â  Â  Â  Â  Â  Â  ordered=True
Â  Â  Â  Â  )

Â  Â  # Clean geojson properties for matching
Â  Â  for feature in geojson_data["features"]:
Â  Â  Â  Â  if geo_feature_id_key == "properties.SUB_DISTRICT" and "SUB_DISTRICT" in feature["properties"]:
Â  Â  Â  Â  Â  Â  feature["properties"]["SUB_DISTRICT"] = feature["properties"]["SUB_DISTRICT"].strip().lower()
Â  Â  Â  Â  elif geo_feature_id_key == "properties.district" and "district" in feature["properties"]:
Â  Â  Â  Â  Â  Â  feature["properties"]["district"] = feature["properties"]["district"].strip().lower()


Â  Â  fig = px.choropleth_mapbox(
Â  Â  Â  Â  df_plot,
Â  Â  Â  Â  geojson=geojson_data,
Â  Â  Â  Â  featureidkey=geo_feature_id_key, # Dynamic key for Taluka or District
Â  Â  Â  Â  locations=geo_location_col,Â  Â  Â # Dynamic column for Taluka or District
Â  Â  Â  Â  color="Rainfall_Category",
Â  Â  Â  Â  color_discrete_map=color_map,
Â  Â  Â  Â  mapbox_style="open-street-map",
Â  Â  Â  Â  zoom=6,
Â  Â  Â  Â  center={"lat": 22.5, "lon": 71.5},
Â  Â  Â  Â  opacity=0.75,
Â  Â  Â  Â  hover_name=geo_location_col, # Use dynamic column for hover name
Â  Â  Â  Â  hover_data={
Â  Â  Â  Â  Â  Â  color_column: ":.1f mm", # Show actual rainfall value
Â  Â  Â  Â  Â  Â  "District": True if geo_location_col == "Taluka" else False, # Only show district for taluka map
Â  Â  Â  Â  Â  Â  "Rainfall_Category":False
Â  Â  Â  Â  },
Â  Â  Â  Â  height=650,
Â  Â  Â  Â  title=title
Â  Â  )
Â  Â  fig.update_layout(
Â  Â  Â  Â  margin={"r":0,"t":0,"l":0,"b":0},
Â  Â  Â  Â  uirevision='true',
Â  Â  Â  Â  showlegend=True, # Ensure legend is shown for map
Â  Â  Â  Â  legend=dict(
Â  Â  Â  Â  Â  Â  orientation="h",
Â  Â  Â  Â  Â  Â  yanchor="top",
Â  Â  Â  Â  Â  Â  y=-0.15,
Â  Â  Â  Â  Â  Â  xanchor="center",
Â  Â  Â  Â  Â  Â  x=0.5,
Â  Â  Â  Â  Â  Â  title_text="Rainfall Categories (mm)",
Â  Â  Â  Â  Â  Â  font=dict(size=10),
Â  Â  Â  Â  Â  Â  itemsizing='constant',
Â  Â  Â  Â  )
Â  Â  )
Â  Â  return fig


# --- show_24_hourly_dashboard function (for Daily Summary tab - NOW INCLUDES ALL DAILY CHARTS) ---
def show_24_hourly_dashboard(df, selected_date):
Â  Â  # Rename 'Rain_Last_24_Hrs' to 'Total_mm' for consistency if it's the 24hr data source
Â  Â  if "Rain_Last_24_Hrs" in df.columns:
Â  Â  Â  Â  df.rename(columns={"Rain_Last_24_Hrs": "Total_mm"}, inplace=True)

Â  Â  required_cols = ["Total_mm", "Taluka", "District"]
Â  Â  for col in required_cols:
Â  Â  Â  Â  if col not in df.columns:
Â  Â  Â  Â  Â  Â  st.error(f"Required column '{col}' not found in the loaded data. Please check your Google Sheet headers for 24-hour data.")
Â  Â  Â  Â  Â  Â  return

Â  Â  df["Total_mm"] = pd.to_numeric(df["Total_mm"], errors='coerce')

Â  Â  # --- NEW CODE START: District Name Standardization ---
Â  Â  # Define mapping for known district name discrepancies
Â  Â  district_name_mapping = {
Â  Â  Â  Â  "Chhota Udepur": "Chhota Udaipur",
Â  Â  Â  Â  "Dangs": "Dang",
Â  Â  Â  Â  "Kachchh": "Kutch",
Â  Â  Â  Â  "Mahesana": "Mehsana",
Â  Â  Â  Â  # Add more mappings here if you discover other mismatches
Â  Â  }

Â  Â  # Apply the mapping to the 'District' column
Â  Â  df['District'] = df['District'].replace(district_name_mapping)

Â  Â  # Ensure consistent casing and stripping for matching with GeoJSON
Â  Â  # This also handles cases where a district name might just have leading/trailing spaces
Â  Â  df['District'] = df['District'].astype(str).str.strip()
Â  Â  # --- NEW CODE END: District Name Standardization ---

Â  Â  title = generate_title_from_date(selected_date)
Â  Â  st.subheader(title)

Â  Â  # ---- Metrics ----
Â  Â  state_avg = df["Total_mm"].mean() if not df["Total_mm"].isnull().all() else 0.0

Â  Â  if not df["Total_mm"].isnull().all() and not df.empty:
Â  Â  Â  Â  highest_taluka = df.loc[df["Total_mm"].idxmax()]
Â  Â  else:
Â  Â  Â  Â  highest_taluka = pd.Series({'Taluka': 'N/A', 'Total_mm': 0})

Â  Â  # The user's code expects columns like `Percent_Against_Avg` to be present
Â  Â  percent_against_avg = df["Percent_Against_Avg"].mean() if "Percent_Against_Avg" in df.columns and not df["Percent_Against_Avg"].isnull().all() else 0.0

Â  Â  col1, col2, col3 = st.columns(3)
Â  Â  with col1:
Â  Â  Â  Â  st.markdown("<div class='metric-container'>", unsafe_allow_html=True)
Â  Â  Â  Â  st.markdown(f"<div class='metric-tile'><h4>State Rainfall (Avg.)</h4><h2>{state_avg:.1f} mm</h2></div>", unsafe_allow_html=True)
Â  Â  Â  Â  st.markdown("</div>", unsafe_allow_html=True)
Â  Â  with col2:
Â  Â  Â  Â  st.markdown("<div class='metric-container'>", unsafe_allow_html=True)
Â  Â  Â  Â  st.markdown(f"<div class='metric-tile'><h4>Highest Rainfall Taluka</h4><h2>{highest_taluka['Taluka']}</h2><p>({highest_taluka['Total_mm']} mm)</p></div>", unsafe_allow_html=True)
Â  Â  Â  Â  st.markdown("</div>", unsafe_allow_html=True)
Â  Â  with col3:
Â  Â  Â  Â  st.markdown("<div class='metric-container'>", unsafe_allow_html=True)
Â  Â  Â  Â  st.markdown(f"<div class='metric-tile'><h4>State Avg Rainfall (%) Till Today</h4><h2>{percent_against_avg:.1f}%</h2></div>", unsafe_allow_html=True)
Â  Â  Â  Â  st.markdown("</div>", unsafe_allow_html=True)

Â  Â  st.markdown("---")
Â  Â  col_daily_1, col_daily_2, col_daily_3 = st.columns(3)

Â  Â  more_than_200_daily = df[df['Total_mm'] > 200].shape[0]
Â  Â  more_than_100_daily = df[df['Total_mm'] > 100].shape[0]
Â  Â  more_than_50_daily = df[df['Total_mm'] > 50].shape[0]

Â  Â  with col_daily_1:
Â  Â  Â  Â  st.markdown("<div class='metric-container'>", unsafe_allow_html=True)
Â  Â  Â  Â  st.markdown(f"<div class='metric-tile'><h4>Talukas > 200 mm</h4><h2>{more_than_200_daily}</h2></div>", unsafe_allow_html=True)
Â  Â  Â  Â  st.markdown("</div>", unsafe_allow_html=True)
Â  Â  with col_daily_2:
Â  Â  Â  Â  st.markdown("<div class='metric-container'>", unsafe_allow_html=True)
Â  Â  Â  Â  st.markdown(f"<div class='metric-tile'><h4>Talukas > 100 mm</h4><h2>{more_than_100_daily}</h2></div>", unsafe_allow_html=True)
Â  Â  Â  Â  st.markdown("</div>", unsafe_allow_html=True)
Â  Â  with col_daily_3:
Â  Â  Â  Â  st.markdown("<div class='metric-container'>", unsafe_allow_html=True)
Â  Â  Â  Â  st.markdown(f"<div class='metric-tile'><h4>Talukas > 50 mm</h4><h2>{more_than_50_daily}</h2></div>", unsafe_allow_html=True)
Â  Â  Â  Â  st.markdown("</div>", unsafe_allow_html=True)

Â  Â  st.markdown("---")

Â  # --- MODIFIED: ZONAL SUMMARY SECTION ---
    st.header("Zonewise Rainfall (Average) Summary Table")

    zonal_summary_averages = get_zonal_data(df_daily_copy)

    if not zonal_summary_averages.empty:
        col_table, col_chart = st.columns([1, 1])
        
        df_daily_renamed_for_table = df_daily_copy.rename(columns={
            'avg_rain': 'Avg_Rain', 'rain_till_yesterday': 'Rain_Till_Yesterday',
            'rain_last_24_hrs': 'Rain_Last_24_Hrs', 'total_rainfall': 'Total_Rainfall',
            'percent_against_avg': 'Percent_Against_Avg'
        })
        
        zonal_summary_table_df = generate_zonal_summary_table(zonal_summary_averages, df_daily_renamed_for_table)

        with col_table:
            st.markdown("#### Rainfall Averages by Zone")
            
            if not zonal_summary_table_df.empty:
                st.dataframe(zonal_summary_table_df.style.set_properties(**{'font-weight': 'bold'}, subset=pd.IndexSlice[-1:, :]), use_container_width=True)
            else:
                st.warning("Could not generate Zonewise Summary. Please ensure your data source contains the required columns and is loaded correctly.")

        with col_chart:
            st.markdown("#### Zonewise Rainfall vs. % Against Avg.")
            fig = create_zonal_dual_axis_chart(zonal_summary_averages)
            st.plotly_chart(fig, use_container_width=True)
    else:
        st.warning("Could not generate Zonewise Summary. Please ensure your data source contains the required columns and is loaded correctly.")
    # --- MODIFIED: END ZONAL SUMMARY SECTION ---

Â  Â  st.markdown("---")
Â  Â  st.markdown("### ğŸ—ºï¸ Rainfall Distribution Overview")

Â  Â  district_rainfall_avg_df = df.groupby('District')['Total_mm'].mean().reset_index()
Â  Â  district_rainfall_avg_df = district_rainfall_avg_df.rename(
Â  Â  Â  Â  columns={'Total_mm': 'District_Avg_Rain_Last_24_Hrs'}
Â  Â  )
Â  Â  district_rainfall_avg_df["Rainfall_Category"] = district_rainfall_avg_df["District_Avg_Rain_Last_24_Hrs"].apply(classify_rainfall)
Â  Â  district_rainfall_avg_df["Rainfall_Category"] = pd.Categorical(
Â  Â  Â  Â  district_rainfall_avg_df["Rainfall_Category"],
Â  Â  Â  Â  categories=ordered_categories,
Â  Â  Â  Â  ordered=True
Â  Â  )
Â  Â  district_rainfall_avg_df['Rainfall_Range'] = district_rainfall_avg_df['Rainfall_Category'].map(category_ranges)


Â  Â  df_map_talukas = df.copy()
Â  Â  df_map_talukas["Taluka"] = df_map_talukas["Taluka"].str.strip().str.lower()
Â  Â  df_map_talukas["Rainfall_Category"] = df_map_talukas["Total_mm"].apply(classify_rainfall)
Â  Â  df_map_talukas["Rainfall_Category"] = pd.Categorical(
Â  Â  Â  Â  df_map_talukas["Rainfall_Category"],
Â  Â  Â  Â  categories=ordered_categories,
Â  Â  Â  Â  ordered=True
Â  Â  )
Â  Â  df_map_talukas["Rainfall_Range"] = df_map_talukas["Rainfall_Category"].map(category_ranges)

Â  Â  taluka_geojson = load_geojson("gujarat_taluka_clean.geojson")
Â  Â  district_geojson = load_geojson("gujarat_district_clean.geojson")


Â  Â  if not taluka_geojson or not district_geojson:
Â  Â  Â  Â  st.error("Cannot display maps: One or both GeoJSON files not found or loaded correctly.")
Â  Â  Â  Â  return

Â  Â  tab_districts, tab_talukas = st.tabs(["Rainfall Distribution by Districts", "Rainfall Distribution by Talukas"])


Â  Â  with tab_districts:
Â  Â  Â  Â  map_col_dist, insights_col_dist = st.columns([0.5, 0.5])

Â  Â  Â  Â  with map_col_dist:
Â  Â  Â  Â  Â  Â  st.markdown("#### Gujarat Rainfall Map (by District)")
Â  Â  Â  Â  Â  Â  with st.spinner("Loading district map..."):
Â  Â  Â  Â  Â  Â  Â  Â  fig_map_districts = plot_choropleth(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  district_rainfall_avg_df,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "gujarat_district_clean.geojson",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  title="Gujarat Daily Rainfall Distribution by District",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  geo_feature_id_key="properties.district",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  geo_location_col="District"
Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  Â  Â  st.plotly_chart(fig_map_districts, use_container_width=True)

Â  Â  Â  Â  with insights_col_dist:
Â  Â  Â  Â  Â  Â  st.markdown("#### Key Insights & Distributions (Districts)")

Â  Â  Â  Â  Â  Â  category_counts_dist = district_rainfall_avg_df['Rainfall_Category'].value_counts().reset_index()
Â  Â  Â  Â  Â  Â  category_counts_dist.columns = ['Category', 'Count']
Â  Â  Â  Â  Â  Â  category_counts_dist['Category'] = pd.Categorical(
Â  Â  Â  Â  Â  Â  Â  Â  category_counts_dist['Category'],
Â  Â  Â  Â  Â  Â  Â  Â  categories=ordered_categories,
Â  Â  Â  Â  Â  Â  Â  Â  ordered=True
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  category_counts_dist = category_counts_dist.sort_values('Category')
Â  Â  Â  Â  Â  Â  category_counts_dist['Rainfall_Range'] = category_counts_dist['Category'].map(category_ranges)


Â  Â  Â  Â  Â  Â  fig_category_dist_dist = px.bar(
Â  Â  Â  Â  Â  Â  Â  Â  category_counts_dist,
Â  Â  Â  Â  Â  Â  Â  Â  x='Category',
Â  Â  Â  Â  Â  Â  Â  Â  y='Count',
Â  Â  Â  Â  Â  Â  Â  Â  title='Distribution of Districts by Daily Rainfall Category',
Â  Â  Â  Â  Â  Â  Â  Â  labels={'Count': 'Number of Districts'},
Â  Â  Â  Â  Â  Â  Â  Â  color='Category',
Â  Â  Â  Â  Â  Â  Â  Â  color_discrete_map=color_map,
Â  Â  Â  Â  Â  Â  Â  Â  hover_data={
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Category': True,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Rainfall_Range': True,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Count': True
Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  fig_category_dist_dist.update_layout(
Â  Â  Â  Â  Â  Â  Â  Â  xaxis=dict(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  tickmode='array',
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  tickvals=category_counts_dist['Category'],
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ticktext=[cat for cat in category_counts_dist['Category']],
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  tickangle=0
Â  Â  Â  Â  Â  Â  Â  Â  ),
Â  Â  Â  Â  Â  Â  Â  Â  xaxis_title=None,
Â  Â  Â  Â  Â  Â  Â  Â  showlegend=False,
Â  Â  Â  Â  Â  Â  Â  Â  height=350,
Â  Â  Â  Â  Â  Â  Â  Â  margin=dict(l=0, r=0, t=50, b=0)
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  st.plotly_chart(fig_category_dist_dist, use_container_width=True)


Â  Â  with tab_talukas:
Â  Â  Â  Â  map_col_tal, insights_col_tal = st.columns([0.5, 0.5])

Â  Â  Â  Â  with map_col_tal:
Â  Â  Â  Â  Â  Â  st.markdown("#### Gujarat Rainfall Map (by Taluka)")
Â  Â  Â  Â  Â  Â  with st.spinner("Loading taluka map..."):
Â  Â  Â  Â  Â  Â  Â  Â  fig_map_talukas = plot_choropleth(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_map_talukas,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "gujarat_taluka_clean.geojson",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  title="Gujarat Daily Rainfall Distribution by Taluka",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  geo_feature_id_key="properties.SUB_DISTRICT",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  geo_location_col="Taluka"
Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  Â  Â  st.plotly_chart(fig_map_talukas, use_container_width=True)

Â  Â  Â  Â  with insights_col_tal:
Â  Â  Â  Â  Â  Â  st.markdown("#### Key Insights & Distributions (Talukas)")

Â  Â  Â  Â  Â  Â  TOTAL_TALUKAS_GUJARAT = 251
Â  Â  Â  Â  Â  Â  num_talukas_with_rain_today = df_map_talukas[df_map_talukas['Total_mm'] > 0].shape[0]
Â  Â  Â  Â  Â  Â  talukas_without_rain = TOTAL_TALUKAS_GUJARAT - num_talukas_with_rain_today

Â  Â  Â  Â  Â  Â  pie_data = pd.DataFrame({
Â  Â  Â  Â  Â  Â  Â  Â  'Category': ['Talukas with Rainfall', 'Talukas without Rainfall'],
Â  Â  Â  Â  Â  Â  Â  Â  'Count': [num_talukas_with_rain_today, talukas_without_rain]
Â  Â  Â  Â  Â  Â  })

Â  Â  Â  Â  Â  Â  fig_pie = px.pie(
Â  Â  Â  Â  Â  Â  Â  Â  pie_data,
Â  Â  Â  Â  Â  Â  Â  Â  values='Count',
Â  Â  Â  Â  Â  Â  Â  Â  names='Category',
Â  Â  Â  Â  Â  Â  Â  Â  title="Percentage of Talukas with Daily Rainfall",
Â  Â  Â  Â  Â  Â  Â  Â  color='Category',
Â  Â  Â  Â  Â  Â  Â  Â  color_discrete_map={
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Talukas with Rainfall': '#28a745',
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Talukas without Rainfall': '#dc3545'
Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  fig_pie.update_traces(textinfo='percent+label', pull=[0.05 if cat == 'Talukas with Rainfall' else 0 for cat in pie_data['Category']])
Â  Â  Â  Â  Â  Â  fig_pie.update_layout(showlegend=False, height=300, margin=dict(l=0, r=0, t=50, b=0))
Â  Â  Â  Â  Â  Â  st.plotly_chart(fig_pie, use_container_width=True)

Â  Â  Â  Â  Â  Â  category_counts_tal = df_map_talukas['Rainfall_Category'].value_counts().reset_index()
Â  Â  Â  Â  Â  Â  category_counts_tal.columns = ['Category', 'Count']
Â  Â  Â  Â  Â  Â  category_counts_tal['Category'] = pd.Categorical(
Â  Â  Â  Â  Â  Â  Â  Â  category_counts_tal['Category'],
Â  Â  Â  Â  Â  Â  Â  Â  categories=ordered_categories,
Â  Â  Â  Â  Â  Â  Â  Â  ordered=True
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  category_counts_tal = category_counts_tal.sort_values('Category')
Â  Â  Â  Â  Â  Â  category_counts_tal['Rainfall_Range'] = category_counts_tal['Category'].map(category_ranges)


Â  Â  Â  Â  Â  Â  fig_category_dist_tal = px.bar(
Â  Â  Â  Â  Â  Â  Â  Â  category_counts_tal,
Â  Â  Â  Â  Â  Â  Â  Â  x='Category',
Â  Â  Â  Â  Â  Â  Â  Â  y='Count',
Â  Â  Â  Â  Â  Â  Â  Â  title='Distribution of Talukas by Daily Rainfall Category',
Â  Â  Â  Â  Â  Â  Â  Â  labels={'Count': 'Number of Talukas'},
Â  Â  Â  Â  Â  Â  Â  Â  color='Category',
Â  Â  Â  Â  Â  Â  Â  Â  color_discrete_map=color_map,
Â  Â  Â  Â  Â  Â  Â  Â  hover_data={
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Category': True,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Rainfall_Range': True,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Count': True
Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  fig_category_dist_tal.update_layout(
Â  Â  Â  Â  Â  Â  Â  Â  xaxis=dict(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  tickmode='array',
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  tickvals=category_counts_tal['Category'],
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ticktext=[cat for cat in category_counts_tal['Category']],
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  tickangle=0
Â  Â  Â  Â  Â  Â  Â  Â  ),
Â  Â  Â  Â  Â  Â  Â  Â  xaxis_title=None,
Â  Â  Â  Â  Â  Â  Â  Â  showlegend=False,
Â  Â  Â  Â  Â  Â  Â  Â  height=350,
Â  Â  Â  Â  Â  Â  Â  Â  margin=dict(l=0, r=0, t=50, b=0)
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  st.plotly_chart(fig_category_dist_tal, use_container_width=True)


Â  Â  st.markdown("---")
Â  Â  st.markdown("### ğŸ† Top 10 Talukas by Total Rainfall")
Â  Â  df_top_10 = df.dropna(subset=['Total_mm']).sort_values(by='Total_mm', ascending=False).head(10)

Â  Â  if not df_top_10.empty:
Â  Â  Â  Â  fig_top_10 = px.bar(
Â  Â  Â  Â  Â  Â  df_top_10,
Â  Â  Â  Â  Â  Â  x='Taluka',
Â  Â  Â  Â  Â  Â  y='Total_mm',
Â  Â  Â  Â  Â  Â  color='Total_mm',
Â  Â  Â  Â  Â  Â  color_continuous_scale=px.colors.sequential.Bluyl,
Â  Â  Â  Â  Â  Â  labels={'Total_mm': 'Total Rainfall (mm)'},
Â  Â  Â  Â  Â  Â  hover_data=['District'],
Â  Â  Â  Â  Â  Â  text='Total_mm',
Â  Â  Â  Â  Â  Â  title='Top 10 Talukas with Highest Total Daily Rainfall'
Â  Â  Â  Â  )
Â  Â  Â  Â  fig_top_10.update_traces(texttemplate='%{text:.1f}', textposition='outside')
Â  Â  Â  Â  fig_top_10.update_layout(
Â  Â  Â  Â  Â  Â  xaxis_tickangle=-45,
Â  Â  Â  Â  Â  Â  showlegend=False,
Â  Â  Â  Â  Â  Â  margin=dict(t=50),
Â  Â  Â  Â  Â  Â  coloraxis_showscale=False
Â  Â  Â  Â  )
Â  Â  Â  Â  st.plotly_chart(fig_top_10, use_container_width=True)
Â  Â  else:
Â  Â  Â  Â  st.info("No rainfall data available to determine top 10 talukas.")

Â  Â  st.subheader("ğŸ“‹ Full Daily Rainfall Data Table")
Â  Â  df_display = df.sort_values(by="Total_mm", ascending=False).reset_index(drop=True)
Â  Â  df_display.index += 1
Â  Â  st.dataframe(df_display, use_container_width=True, height=400)


# ---------------------------- UI ----------------------------
st.set_page_config(layout="wide")
st.markdown("<div class='title-text'>ğŸŒ§ï¸ Gujarat Rainfall Dashboard</div>", unsafe_allow_html=True)

st.markdown("---")
st.subheader("ğŸ—“ï¸ Select Date for Rainfall Data")

if 'selected_date' not in st.session_state:
Â  Â  st.session_state.selected_date = datetime.today().date()

col_date_picker, col_prev_btn, col_today_btn, col_next_btn = st.columns([0.2, 0.1, 0.1, 0.1])

with col_date_picker:
Â  Â  selected_date_from_picker = st.date_input(
Â  Â  Â  Â  "Choose Date",
Â  Â  Â  Â  value=st.session_state.selected_date,
Â  Â  Â  Â  help="Select a specific date to view its rainfall summary."
Â  Â  )
Â  Â  if selected_date_from_picker != st.session_state.selected_date:
Â  Â  Â  Â  st.session_state.selected_date = selected_date_from_picker
Â  Â  Â  Â  st.rerun()

selected_date = st.session_state.selected_date

with col_prev_btn:
Â  Â  st.markdown("<br>", unsafe_allow_html=True)
Â  Â  if st.button("â¬…ï¸ Previous Day", key="prev_day_btn"):
Â  Â  Â  Â  st.session_state.selected_date = selected_date - timedelta(days=1)
Â  Â  Â  Â  st.rerun()

with col_today_btn:
Â  Â  st.markdown("<br>", unsafe_allow_html=True)
Â  Â  if st.button("ğŸ—“ï¸ Today", key="today_btn"):
Â  Â  Â  Â  st.session_state.selected_date = datetime.today().date()
Â  Â  Â  Â  st.rerun()

with col_next_btn:
Â  Â  st.markdown("<br>", unsafe_allow_html=True)
Â  Â  if st.button("Next Day â¡ï¸", key="next_day_btn", disabled=(selected_date >= datetime.today().date())):
Â  Â  Â  Â  st.session_state.selected_date = selected_date + timedelta(days=1)
Â  Â  Â  Â  st.rerun()

st.markdown("---")

selected_year = selected_date.strftime("%Y")
selected_month = selected_date.strftime("%B")
selected_date_str = selected_date.strftime("%Y-%m-%d")

tab_daily, tab_hourly, tab_historical = st.tabs(["Daily Summary", "Hourly Trends", "Historical Data (Coming Soon)"])

with tab_daily:
Â  Â  st.header("Daily Rainfall Summary")

Â  Â  sheet_name_24hr = f"24HR_Rainfall_{selected_month}_{selected_year}"
Â  Â  tab_name_24hr = f"master24hrs_{selected_date_str}"

Â  Â  df_24hr = load_sheet_data(sheet_name_24hr, tab_name_24hr)

Â  Â  if not df_24hr.empty:
Â  Â  Â  Â  show_24_hourly_dashboard(df_24hr, selected_date)
Â  Â  else:
Â  Â  Â  Â  st.warning(f"âš ï¸ Daily data is not available for {selected_date_str}.")

with tab_hourly:
Â  Â  st.header("Hourly Rainfall Trends (2-Hourly)")
Â  Â  sheet_name_2hr = f"2HR_Rainfall_{selected_month}_{selected_year}"
Â  Â  tab_name_2hr = f"2hrs_master_{selected_date_str}"

Â  Â  df_2hr = load_sheet_data(sheet_name_2hr, tab_name_2hr)

Â  Â  if not df_2hr.empty:
Â  Â  Â  Â  df_2hr.columns = df_2hr.columns.str.strip()

Â  Â  Â  Â  time_slot_columns = [col for col in df_2hr.columns if "TO" in col and df_2hr[col].dtype in ['int64', 'float64', 'object']]
Â  Â  Â  Â  time_slot_order = ['06TO08', '08TO10', '10TO12', '12TO14', '14TO16', '16TO18',
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â '18TO20', '20TO22', '22TO24', '24TO02', '02TO04', '04TO06']
Â  Â  Â  Â  existing_order = [slot for slot in time_slot_order if slot in time_slot_columns]

Â  Â  Â  Â  for col in existing_order:
Â  Â  Â  Â  Â  Â  df_2hr[col] = pd.to_numeric(df_2hr[col], errors="coerce")

Â  Â  Â  Â  df_2hr['Total_mm'] = df_2hr[existing_order].sum(axis=1)

Â  Â  Â  Â  df_long = df_2hr.melt(
Â  Â  Â  Â  Â  Â  id_vars=["District", "Taluka", "Total_mm"],
Â  Â  Â  Â  Â  Â  value_vars=existing_order,
Â  Â  Â  Â  Â  Â  var_name="Time Slot",
Â  Â  Â  Â  Â  Â  value_name="Rainfall (mm)"
Â  Â  Â  Â  )
Â  Â  Â  Â  df_long = df_long.dropna(subset=["Rainfall (mm)"])
Â  Â  Â  Â  df_long['Taluka'] = df_long['Taluka'].str.strip()

Â  Â  Â  Â  df_long = df_long.groupby(["District", "Taluka", "Time Slot"], as_index=False).agg({
Â  Â  Â  Â  Â  Â  "Rainfall (mm)": "sum",
Â  Â  Â  Â  Â  Â  "Total_mm": "first"
Â  Â  Â  Â  })

Â  Â  Â  Â  slot_labels = {
Â  Â  Â  Â  Â  Â  "06TO08": "6â€“8 AM", "08TO10": "8â€“10 AM", "10TO12": "10â€“12 AM",
Â  Â  Â  Â  Â  Â  "12TO14": "12â€“2 PM", "14TO16": "2â€“4 PM", "16TO18": "4â€“6 PM",
Â  Â  Â  Â  Â  Â  "18TO20": "6â€“8 PM", "20TO22": "8â€“10 PM", "22TO24": "10â€“12 PM",
Â  Â  Â  Â  Â  Â  "24TO02": "12â€“2 AM", "02TO04": "2â€“4 AM", "04TO06": "4â€“6 AM",
Â  Â  Â  Â  }
Â  Â  Â  Â  df_long['Time Slot Label'] = pd.Categorical(
Â  Â  Â  Â  Â  Â  df_long['Time Slot'].map(slot_labels),
Â  Â  Â  Â  Â  Â  categories=[slot_labels[slot] for slot in existing_order],
Â  Â  Â  Â  Â  Â  ordered=True
Â  Â  Â  Â  )
Â  Â  Â  Â  df_long = df_long.sort_values(by=["Taluka", "Time Slot Label"])


Â  Â  Â  Â  df_2hr['Total_mm'] = pd.to_numeric(df_2hr['Total_mm'], errors='coerce')

Â  Â  Â  Â  top_taluka_row = df_2hr.sort_values(by='Total_mm', ascending=False).iloc[0] if not df_2hr['Total_mm'].dropna().empty else pd.Series({'Taluka': 'N/A', 'Total_mm': 0})
Â  Â  Â  Â  df_latest_slot = df_long[df_long['Time Slot'] == existing_order[-1]]
Â  Â  Â  Â  top_latest = df_latest_slot.sort_values(by='Rainfall (mm)', ascending=False).iloc[0] if not df_latest_slot['Rainfall (mm)'].dropna().empty else pd.Series({'Taluka': 'N/A', 'Rainfall (mm)': 0})
Â  Â  Â  Â  num_talukas_with_rain_hourly = df_2hr[df_2hr['Total_mm'] > 0].shape[0]

Â  Â  Â  Â  st.markdown(f"#### ğŸ“Š Latest data available for time interval: **{slot_labels[existing_order[-1]]}**")

Â  Â  Â  Â  row1 = st.columns(3)

Â  Â  Â  Â  last_slot_label = slot_labels[existing_order[-1]]

Â  Â  Â  Â  row1_titles = [
Â  Â  Â  Â  Â  Â  ("Total Talukas with Rainfall", num_talukas_with_rain_hourly),
Â  Â  Â  Â  Â  Â  ("Top Taluka by Total Rainfall", f"{top_taluka_row['Taluka']}<br><p>{top_taluka_row['Total_mm']:.1f} mm</p>"),
Â  Â  Â  Â  Â  Â  (f"Top Taluka in last 2 hour ({last_slot_label})", f"{top_latest['Taluka']}<br><p>{top_latest['Rainfall (mm)']:.1f} mm</p>")
Â  Â  Â  Â  ]

Â  Â  Â  Â  for col, (label, value) in zip(row1, row1_titles):
Â  Â  Â  Â  Â  Â  with col:
Â  Â  Â  Â  Â  Â  Â  Â  st.markdown("<div class='metric-container'>", unsafe_allow_html=True)
Â  Â  Â  Â  Â  Â  Â  Â  st.markdown(f"<div class='metric-tile'><h4>{label}</h4><h2>{value}</h2></div>", unsafe_allow_html=True)
Â  Â  Â  Â  Â  Â  Â  Â  st.markdown("</div>", unsafe_allow_html=True)

Â  Â  Â  Â  st.markdown("### ğŸ“ˆ Rainfall Trend by 2 hourly Time Interval")
Â  Â  Â  Â  selected_talukas = st.multiselect("Select Taluka(s)", sorted(df_long['Taluka'].unique()), default=[top_taluka_row['Taluka']] if top_taluka_row['Taluka'] != 'N/A' else [])

Â  Â  Â  Â  if selected_talukas:
Â  Â  Â  Â  Â  Â  plot_df = df_long[df_long['Taluka'].isin(selected_talukas)]
Â  Â  Â  Â  Â  Â  fig = px.line(
Â  Â  Â  Â  Â  Â  Â  Â  plot_df,
Â  Â  Â  Â  Â  Â  Â  Â  x="Time Slot Label",
Â  Â  Â  Â  Â  Â  Â  Â  y="Rainfall (mm)",
Â  Â  Â  Â  Â  Â  Â  Â  color="Taluka",
Â  Â  Â  Â  Â  Â  Â  Â  markers=True,
Â  Â  Â  Â  Â  Â  Â  Â  text="Rainfall (mm)",
Â  Â  Â  Â  Â  Â  Â  Â  title="Rainfall Trend Over Time for Selected Talukas",
Â  Â  Â  Â  Â  Â  Â  Â  labels={"Rainfall (mm)": "Rainfall (mm)"}
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  fig.update_traces(textposition="top center")
Â  Â  Â  Â  Â  Â  fig.update_layout(showlegend=True)
Â  Â  Â  Â  Â  Â  fig.update_layout(modebar_remove=['toImage'])
Â  Â  Â  Â  Â  Â  st.plotly_chart(fig, use_container_width=True)
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  st.info("Please select at least one Taluka to view the rainfall trend.")


Â  Â  Â  Â  st.markdown("### ğŸ“‹ Full 2-Hourly Rainfall Data Table")
Â  Â  Â  Â  df_display_2hr = df_2hr.sort_values(by="Total_mm", ascending=False).reset_index(drop=True)
Â  Â  Â  Â  df_display_2hr.index += 1
Â  Â  Â  Â  st.dataframe(df_display_2hr, use_container_width=True, height=600)

Â  Â  else:
Â  Â  Â  Â  st.warning(f"âš ï¸ 2-Hourly data is not available for {selected_date_str}.")


with tab_historical:
Â  Â  st.header("Historical Rainfall Data")
Â  Â  st.info("ğŸ’¡ **Coming Soon:** This section will feature monthly/seasonal data, year-on-year comparisons, and long-term trends.")
